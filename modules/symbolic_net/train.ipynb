{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "repo_start = f'../../'\n",
    "sys.path.append(repo_start)\n",
    "\n",
    "from modules.utils.imports import *\n",
    "from modules.symbolic_net.model_wrapper import model_wrapper\n",
    "from modules.symbolic_net.build_symbolic_net import symbolic_net\n",
    "from modules.binn.build_binns_2d_diffusion import BINN\n",
    "from modules.utils.training_test_split import training_test_split\n",
    "from modules.analysis.generate_loss_curves import generate_loss_curves\n",
    "from modules.loaders.format_data import format_data_general\n",
    "from modules.generate_data.simulate_system import reaction\n",
    "from modules.symbolic_net.write_terms import write_terms\n",
    "from modules.symbolic_net.visualize_surface import visualize_surface\n",
    "from modules.symbolic_net.individual import individual\n",
    "\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "torch.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load symbolic net parameters from config file\n",
    "\n",
    "dir_name = '/work/users/s/m/smyersn/elston/projects/kinetics_binns/development/equation_fitting/symbolic_net/runs/repeat_10_10k_stop_50_repeats/param_bounds_symbolic_net_l1_reg_0.1_repeat_1_lr_0.001'\n",
    "\n",
    "config = {}\n",
    "exec(Path(f'{dir_name}/config.cfg').read_text(encoding=\"utf8\"), {}, config)\n",
    "\n",
    "training_data_path = config['training_data_path']\n",
    "species = int(config['species'])\n",
    "degree = int(config['degree'])\n",
    "nonzero_term_reg = int(config['nonzero_term_reg'])\n",
    "l1_reg = float(config['l1_reg'])\n",
    "param_bounds = float(config['param_bounds'])\n",
    "density_weight = float(config['density_weight'])\n",
    "learning_rate = float(config['learning_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TRAINING\n",
    "\n",
    "# Set training hyperparameters\n",
    "epochs = int(1e6)\n",
    "rel_save_thresh = 0.05\n",
    "device = 'cpu'\n",
    "\n",
    "# Generate training data\n",
    "training_data = format_data_general(2, 2, file=training_data_path)\n",
    "uv = training_data[:, -2:]\n",
    "u_triangle_mesh, v_triangle_mesh = lltriangle(uv[:, 0], uv[:, 1])\n",
    "u, v = np.ravel(u_triangle_mesh), np.ravel(v_triangle_mesh)\n",
    "\n",
    "a, b ,k = 1, 1, 0.01\n",
    "F_true = reaction(u, v, a, b, k)\n",
    "\n",
    "training_data_nans = np.stack((u, v, F_true), axis=1)\n",
    "\n",
    "# Remove nans from training data\n",
    "mask = ~np.isnan(training_data_nans).any(axis=1)\n",
    "training_data = training_data_nans[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load BINN parameters from config file\n",
    "\n",
    "dir_name = '/work/users/s/m/smyersn/elston/projects/kinetics_binns/development/binn_testing/debugged_development/comprehensive/runs/2d_repeats/2d_alpha_0.5_repeat_5'\n",
    "config = {}\n",
    "exec(Path(f'{dir_name}/config.cfg').read_text(encoding=\"utf8\"), {}, config)\n",
    "\n",
    "training_data_path = config['training_data_path']\n",
    "dimensions = int(config['dimensions'])\n",
    "species = int(config['species'])\n",
    "\n",
    "density_weight = int(config['density_weight'])\n",
    "\n",
    "uv_layers = int(config['uv_layers'])\n",
    "uv_neurons = int(config['uv_neurons'])\n",
    "f_layers = int(config['f_layers'])\n",
    "f_neurons = int(config['f_neurons'])\n",
    "\n",
    "epsilon = float(config['epsilon'])\n",
    "points = int(config['points'])\n",
    "\n",
    "diffusion = bool(config['diffusion'])\n",
    "alpha = float(config['alpha'])\n",
    "\n",
    "uv_arch = uv_layers * [uv_neurons] + [2]\n",
    "f_arch = f_layers * [f_neurons] + [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize BINN\n",
    "\n",
    "binn = BINN(\n",
    "    species=species, \n",
    "    dimensions=dimensions,\n",
    "    uv_layers=uv_arch, \n",
    "    f_layers=f_arch,\n",
    "    diff=diffusion)\n",
    "\n",
    "binn.to(device)\n",
    "\n",
    "opt = torch.optim.Adam(list(binn.parameters()), lr=1e-3)\n",
    "model = model_wrapper(\n",
    "    model=binn,\n",
    "    optimizer=opt,\n",
    "    loss=binn.loss,\n",
    "    augmentation=None,\n",
    "    save_name=f'{dir_name}/binn')\n",
    "\n",
    "model.load(f\"{dir_name}/binn_best_val_model\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TRAINING\n",
    "\n",
    "# Set training hyperparameters\n",
    "epochs = int(1e6)\n",
    "rel_save_thresh = 0.05\n",
    "device = 'cpu'\n",
    "\n",
    "# Generate training data\n",
    "training_data = format_data_general(2, 2, file=training_data_path)\n",
    "uv = training_data[:, -2:]\n",
    "u_triangle_mesh, v_triangle_mesh = lltriangle(uv[:, 0], uv[:, 1])\n",
    "u, v = np.ravel(u_triangle_mesh), np.ravel(v_triangle_mesh)\n",
    "\n",
    "# Calculate true surface to fit to\n",
    "uv = np.column_stack((np.ravel(u_triangle_mesh), np.ravel(v_triangle_mesh)))\n",
    "F_true = to_numpy(model.model.reaction(to_torch(uv)[:, None])).flatten()\n",
    "\n",
    "training_data_nans = np.stack((u, v, F_true), axis=1)\n",
    "\n",
    "# Remove nans from training data\n",
    "mask = ~np.isnan(training_data_nans).any(axis=1)\n",
    "training_data = training_data_nans[mask]\n",
    "\n",
    "# Split training data\n",
    "x_train, y_train, x_val, y_val = training_test_split(training_data, 1, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize model\n",
    "device = torch.device('cpu')\n",
    "\n",
    "binn = BINN(\n",
    "    species=species, \n",
    "    dimensions=dimensions,\n",
    "    uv_layers=uv_arch, \n",
    "    f_layers=f_arch,\n",
    "    diff=diffusion)\n",
    "\n",
    "binn.to(device)\n",
    "\n",
    "opt = torch.optim.Adam(list(binn.parameters()), lr=1e-3)\n",
    "model = model_wrapper(\n",
    "    model=binn,\n",
    "    optimizer=opt,\n",
    "    loss=binn.loss,\n",
    "    augmentation=None,\n",
    "    save_name=f'{dir_name}/binn')\n",
    "\n",
    "model.load(f\"{dir_name}/binn_best_val_model\", device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = x_train[:, 0].flatten()\n",
    "v = x_train[:, 1].flatten()\n",
    "\n",
    "hist = torchist.normalize(torchist.histogramdd(x_train, bins=10, \n",
    "                            low=[min(u).item(), min(v).item()], \n",
    "                            upp=[max(u).item(), max(v).item()]))[0]\n",
    "\n",
    "edges = torchist.histogramdd_edges(x_train, bins=10, \n",
    "                                low=[min(u).item(), min(v).item()], \n",
    "                                upp=[max(u).item(), max(v).item()])\n",
    "edges[0] = edges[0].to(device)\n",
    "edges[1] = edges[1].to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2023, 0.2845, 0.3666, 0.4488, 0.5310, 0.6132, 0.6953, 0.7775, 0.8597,\n",
       "        0.9419, 1.0240])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_density(uv, hist, edges):\n",
    "    uv_indices = torch.zeros((len(uv), len(uv.T)))\n",
    "    # iterate over columns\n",
    "    for i in range(len(uv.T)):\n",
    "        buckets = torch.bucketize(uv[:, i], edges[i], right=True)\n",
    "        # convert from buckets to indices, correct so max value falls in last bucket\n",
    "        indices = torch.where(buckets != 0, buckets-1, buckets)\n",
    "        indices_corrected = torch.where(indices == len(edges[i])-1, indices-1, indices)\n",
    "        uv_indices[:, i] = indices_corrected\n",
    "        \n",
    "    density = torch.tensor([hist[int(indices[0]), int(indices[1])] for indices in uv_indices])\n",
    "        \n",
    "    return density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0202, 0.0010, 0.0010])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uv = torch.tensor([[5, 0.1], [1, 1], [11, 1]])\n",
    "calc_density(uv, hist, edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load BINN parameters from config file\n",
    "dir_name = '/work/users/s/m/smyersn/elston/projects/kinetics_binns/development/binn_testing/debugged_development/comprehensive/runs/2d_repeats/2d_alpha_0.5_repeat_5'\n",
    "config = {}\n",
    "exec(Path(f'{dir_name}/config.cfg').read_text(encoding=\"utf8\"), {}, config)\n",
    "\n",
    "training_data_path = config['training_data_path']\n",
    "dimensions = int(config['dimensions'])\n",
    "species = int(config['species'])\n",
    "\n",
    "density_weight = int(config['density_weight'])\n",
    "\n",
    "uv_layers = int(config['uv_layers'])\n",
    "uv_neurons = int(config['uv_neurons'])\n",
    "f_layers = int(config['f_layers'])\n",
    "f_neurons = int(config['f_neurons'])\n",
    "\n",
    "epsilon = float(config['epsilon'])\n",
    "points = int(config['points'])\n",
    "\n",
    "diffusion = bool(config['diffusion'])\n",
    "alpha = float(config['alpha'])\n",
    "\n",
    "uv_arch = uv_layers * [uv_neurons] + [2]\n",
    "f_arch = f_layers * [f_neurons] + [1]\n",
    "\n",
    "# Set training hyperparameters\n",
    "epochs = int(1e6)\n",
    "rel_save_thresh = 0.05\n",
    "device = 'cpu'\n",
    "\n",
    "# Initialize BINN\n",
    "binn = BINN(\n",
    "    species=species, \n",
    "    dimensions=dimensions,\n",
    "    uv_layers=uv_arch, \n",
    "    f_layers=f_arch,\n",
    "    diff=diffusion)\n",
    "\n",
    "binn.to(device)\n",
    "\n",
    "opt = torch.optim.Adam(list(binn.parameters()), lr=1e-3)\n",
    "model = model_wrapper(\n",
    "    model=binn,\n",
    "    optimizer=opt,\n",
    "    loss=binn.loss,\n",
    "    augmentation=None,\n",
    "    save_name=f'{dir_name}/binn')\n",
    "\n",
    "model.load(f\"{dir_name}/binn_best_val_model\", device=device)\n",
    "\n",
    "# Generate training data\n",
    "training_data = format_data_general(2, 2, file=training_data_path)\n",
    "uv = training_data[:, -2:]\n",
    "u_triangle_mesh, v_triangle_mesh = lltriangle(uv[:, 0], uv[:, 1])\n",
    "u, v = np.ravel(u_triangle_mesh), np.ravel(v_triangle_mesh)\n",
    "\n",
    "# Calculate true surface to fit (F_mlp)\n",
    "uv = np.column_stack((np.ravel(u_triangle_mesh), np.ravel(v_triangle_mesh)))\n",
    "F_true = to_numpy(model.model.reaction(to_torch(uv)[:, None])).flatten()\n",
    "\n",
    "training_data_nans = np.stack((u, v, F_true), axis=1)\n",
    "\n",
    "# Remove nans from training data\n",
    "mask = ~np.isnan(training_data_nans).any(axis=1)\n",
    "training_data = training_data_nans[mask]\n",
    "\n",
    "# Split training data\n",
    "x_train, y_train, x_val, y_val = training_test_split(training_data, 1, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_name = '/work/users/s/m/smyersn/elston/projects/kinetics_binns/development/equation_fitting/symbolic_net/runs/param_bounds_symbolic_net_l1_reg_0.1_lr_0.001'\n",
    "config = {}\n",
    "exec(Path(f'{dir_name}/config.cfg').read_text(encoding=\"utf8\"), {}, config)\n",
    "\n",
    "training_data_path = config['training_data_path']\n",
    "species = int(config['species'])\n",
    "degree = int(config['degree'])\n",
    "nonzero_term_reg = int(config['nonzero_term_reg'])\n",
    "l1_reg = float(config['l1_reg'])\n",
    "param_bounds = float(config['param_bounds'])\n",
    "density_weight = float(config['density_weight'])\n",
    "learning_rate = float(config['learning_rate'])\n",
    "\n",
    "device = 'cpu'\n",
    "# initialize model and compile\n",
    "sym_net = symbolic_net(species, degree, param_bounds, device, l1_reg,\n",
    "                       nonzero_term_reg)\n",
    "sym_net.to(device)\n",
    "\n",
    "# initialize optimizer\n",
    "parameters = sym_net.parameters()\n",
    "opt = torch.optim.Adam(parameters, lr=learning_rate)\n",
    "\n",
    "model = model_wrapper(\n",
    "    model=sym_net,\n",
    "    optimizer=opt,\n",
    "    loss=sym_net.loss,\n",
    "    augmentation=None,\n",
    "    save_name=f'{dir_name}/binn')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "binns",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
